# ============================================
# LLM PROVIDER CONFIGURATION
# ============================================
# Options: "ollama", "openrouter", "openai", "github"
# Ollama: Local, fast, no rate limits (RECOMMENDED)
# GitHub Models: Remote, free tier, requires GitHub PAT
# OpenRouter: Remote, free tier has strict rate limits (429 errors)
LLM_PROVIDER=github

# Embeddings provider (can be different from LLM_PROVIDER)
# Options: "ollama"
EMBEDDINGS_PROVIDER=ollama

# ============================================
# OLLAMA (Local)
# ============================================
OLLAMA_API_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
OLLAMA_EMBEDDINGS_MODEL=nomic-embed-text

# ============================================
# GITHUB MODELS (Remote - Recommended)
# ============================================
# Get your Personal Access Token at: https://github.com/settings/tokens
# Required scope: models:read
# Endpoint: https://models.github.ai/inference/chat/completions
#
# Para obtener lista actualizada de modelos:
# curl -L -H "Accept: application/vnd.github+json" \
#   -H "Authorization: Bearer YOUR_TOKEN" \
#   -H "X-GitHub-Api-Version: 2022-11-28" \
#   https://models.github.ai/catalog/models
#
GITHUB_TOKEN=
#
# MODELOS DISPONIBLES (42 total):
#
# OpenAI (texto + imágenes):
#   - openai/gpt-5              Logic-heavy, multi-step (200K ctx, 100K out)
#   - openai/gpt-5-chat         Advanced conversations (200K ctx, 100K out)
#   - openai/gpt-5-mini         Cost-sensitive (200K ctx, 100K out) ⭐ RECOMENDADO
#   - openai/gpt-5-nano         Low latency (200K ctx, 100K out)
#   - openai/gpt-4.1            Best coding/reasoning (1M ctx, 32K out)
#   - openai/gpt-4.1-mini       Balanced (1M ctx, 32K out)
#   - openai/gpt-4.1-nano       Lower cost (1M ctx, 32K out)
#   - openai/gpt-4o             Advanced multimodal (131K ctx)
#   - openai/gpt-4o-mini        Efficient & affordable (131K ctx)
#   - openai/o1                 Advanced reasoning (200K ctx)
#   - openai/o1-mini            Faster reasoning (128K ctx)
#   - openai/o1-preview         Reasoning preview (128K ctx)
#   - openai/o3                 Quality + safety (200K ctx)
#   - openai/o3-mini            Cost-efficient reasoning (200K ctx)
#   - openai/o4-mini            Improved o3-mini (200K ctx)
#
# Meta Llama (open source):
#   - meta/llama-4-scout-17b-16e-instruct     10M context! Codebases (10M ctx)
#   - meta/llama-4-maverick-17b-128e-instruct Image understanding (1M ctx)
#   - meta/meta-llama-3.1-405b-instruct       Best performance (131K ctx)
#   - meta/llama-3.3-70b-instruct             Enhanced reasoning (128K ctx)
#   - meta/llama-3.2-90b-vision-instruct      Vision + reasoning (128K ctx)
#   - meta/llama-3.2-11b-vision-instruct      Vision low-tier (128K ctx)
#   - meta/meta-llama-3.1-8b-instruct         Fast & free (131K ctx)
#
# DeepSeek (reasoning specialist):
#   - deepseek/deepseek-r1-0528    Improved reasoning, less hallucinations
#   - deepseek/deepseek-r1         Original reasoning model
#   - deepseek/deepseek-v3-0324    Enhanced code generation
#
# Microsoft Phi (low latency):
#   - microsoft/phi-4-multimodal-instruct  Text+audio+image (128K ctx)
#   - microsoft/phi-4-reasoning            State-of-the-art reasoning (32K ctx)
#   - microsoft/phi-4-mini-reasoning       Lightweight math (128K ctx)
#   - microsoft/phi-4-mini-instruct        3.8B params, fast (128K ctx)
#   - microsoft/phi-4                      Low latency 14B (16K ctx)
#   - microsoft/mai-ds-r1                  Enhanced DeepSeek-R1 (128K ctx)
#
# Mistral AI:
#   - mistral-ai/mistral-medium-2505  Vision + reasoning (128K ctx)
#   - mistral-ai/mistral-small-2503   Multimodal (128K ctx)
#   - mistral-ai/codestral-2501       80+ languages code (256K ctx)
#   - mistral-ai/ministral-3b         Edge computing (131K ctx)
#
# xAI Grok (specialized domains):
#   - xai/grok-3       Finance/healthcare/law (131K ctx)
#   - xai/grok-3-mini  Logic-based tasks (131K ctx)
#
# Cohere (RAG optimized):
#   - cohere/cohere-command-r-plus-08-2024  Enterprise RAG (131K ctx)
#   - cohere/cohere-command-r-08-2024       Scalable RAG (131K ctx)
#   - cohere/cohere-command-a               Agentic multilingual (131K ctx)
#
# AI21 Labs:
#   - ai21-labs/ai21-jamba-1.5-large  398B params, 256K context
#
# Embeddings:
#   - openai/text-embedding-3-small   Ligero, RAG (8K ctx)
#   - openai/text-embedding-3-large   Mejor calidad (8K ctx)
#
GITHUB_MODEL=openai/gpt-5-mini
# Optional: Site information for API headers
GITHUB_SITE_URL=http://localhost:3000
GITHUB_SITE_NAME=SPARQL Naturalizer

# ============================================
# OPENAI (Remote)
# ============================================
OPENAI_API_KEY=
OPENAI_MODEL=gpt-5-mini